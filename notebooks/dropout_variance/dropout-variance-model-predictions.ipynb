{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import tensorflow as tf\n",
    "print('tensorflow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "## seed and defaults\n",
    "######################################################\n",
    "\n",
    "seed = 2020\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "    \n",
    "\n",
    "DATA_DIR = '../../input/osic-pulmonary-fibrosis-progression'\n",
    "GROUP_SPLITS = 5\n",
    "\n",
    "TRAINING_FEATURES = [\n",
    "    'Female', \n",
    "    'Male',\n",
    "    'Currently smokes', \n",
    "    'Ex-smoker', \n",
    "    'Never smoked',\n",
    "    'Percent',\n",
    "    #'init_week_Percent',\n",
    "    'Age', \n",
    "    'relative_week', \n",
    "    'init_week_FVC'\n",
    "]\n",
    "\n",
    "SCALED_FEATURES = [\n",
    "    'Percent', \n",
    "    'Age',\n",
    "    'relative_week', \n",
    "    'init_week_FVC'\n",
    "]\n",
    "\n",
    "IMG_SIZE = 224\n",
    "IMG_SLICES = 12\n",
    "CUTOFF = 2\n",
    "\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 10\n",
    "BATCH_PRED = 1\n",
    "MODEL_NAME = 'dropout_variance'\n",
    "MODEL_VERSION = 'v11b'\n",
    "MODEL = MODEL_NAME + '_' + MODEL_VERSION + '_batch_' + str(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "## get files and split tabular data\n",
    "######################################################\n",
    "\n",
    "train = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "train.drop_duplicates(keep=False, inplace=True, subset=['Patient','Weeks'])\n",
    "\n",
    "test = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "subm = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')\n",
    "\n",
    "subm['Patient'] = subm['Patient_Week'].apply(lambda x: x.split('_')[0])\n",
    "subm['Weeks'] = subm['Patient_Week'].apply(lambda x: int(x.split('_')[-1]))\n",
    "\n",
    "subm =  subm[['Patient','Weeks','Confidence','Patient_Week']]\n",
    "subm = subm.merge(test.drop('Weeks', axis=1), on='Patient')\n",
    "\n",
    "train['SPLIT'] = 'train'\n",
    "test['SPLIT'] = 'test'\n",
    "subm['SPLIT'] = 'submission'\n",
    "\n",
    "data = train.append([test, subm])\n",
    "\n",
    "######################################################\n",
    "## initial week and relative week augmentations\n",
    "######################################################\n",
    "\n",
    "data['init_week'] = data['Weeks']\n",
    "data.loc[data.SPLIT == 'submission', 'init_week'] = np.nan\n",
    "data['init_week'] = data.groupby('Patient')['init_week'].transform('min')\n",
    "data['relative_week'] = data['Weeks'] - data['init_week']\n",
    "\n",
    "######################################################\n",
    "## add initial fvc to all patients rows\n",
    "######################################################\n",
    "\n",
    "init_fvc = data.groupby('Patient')[['Patient', 'Weeks', 'init_week', 'FVC']].head()\n",
    "init_fvc = init_fvc.loc[init_fvc.Weeks == init_fvc.init_week]\n",
    "init_fvc.columns = ['Patient', 'Weeks', 'init_week', 'init_week_FVC']\n",
    "init_fvc.drop(['Weeks', 'init_week'], axis=1, inplace=True)\n",
    "data = data.merge(init_fvc, on='Patient', how='left')\n",
    "\n",
    "del init_fvc\n",
    "\n",
    "\n",
    "######################################################\n",
    "## scale the continuous variables\n",
    "## and dummies of categories\n",
    "######################################################\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "data[SCALED_FEATURES] = min_max_scaler.fit_transform(data[SCALED_FEATURES])\n",
    "data = pd.concat([data, pd.get_dummies(data.Sex), pd.get_dummies(data.SmokingStatus)], axis=1)\n",
    "\n",
    "######################################################\n",
    "## add initial percent to all patients rows\n",
    "######################################################\n",
    "\n",
    "init_perc = data.groupby('Patient')[['Patient', 'Weeks', 'init_week', 'Percent']].head()\n",
    "init_perc = init_perc.loc[init_perc.Weeks == init_perc.init_week]\n",
    "init_perc.columns = ['Patient', 'Weeks', 'init_week', 'init_week_Percent']\n",
    "init_perc.drop(['Weeks', 'init_week'], axis=1, inplace=True)\n",
    "data = data.merge(init_perc, on='Patient', how='left')\n",
    "\n",
    "del init_perc\n",
    "\n",
    "######################################################\n",
    "## separate for training, testing, submission\n",
    "######################################################\n",
    "\n",
    "train = data.loc[data.SPLIT == 'train']\n",
    "test = data.loc[data.SPLIT == 'test']\n",
    "subm = data.loc[data.SPLIT == 'submission']\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Weeks</th>\n",
       "      <th>FVC</th>\n",
       "      <th>Percent</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SmokingStatus</th>\n",
       "      <th>SPLIT</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Patient_Week</th>\n",
       "      <th>init_week</th>\n",
       "      <th>relative_week</th>\n",
       "      <th>init_week_FVC</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "      <th>Currently smokes</th>\n",
       "      <th>Ex-smoker</th>\n",
       "      <th>Never smoked</th>\n",
       "      <th>init_week_Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>ID00419637202311204720264</td>\n",
       "      <td>-12</td>\n",
       "      <td>3020</td>\n",
       "      <td>0.332421</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>submission</td>\n",
       "      <td>100.0</td>\n",
       "      <td>ID00419637202311204720264_-12</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.067901</td>\n",
       "      <td>0.3724</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.332421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>ID00419637202311204720264</td>\n",
       "      <td>-11</td>\n",
       "      <td>3020</td>\n",
       "      <td>0.332421</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>submission</td>\n",
       "      <td>100.0</td>\n",
       "      <td>ID00419637202311204720264_-11</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.3724</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.332421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>ID00419637202311204720264</td>\n",
       "      <td>-10</td>\n",
       "      <td>3020</td>\n",
       "      <td>0.332421</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>submission</td>\n",
       "      <td>100.0</td>\n",
       "      <td>ID00419637202311204720264_-10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.080247</td>\n",
       "      <td>0.3724</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.332421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>ID00419637202311204720264</td>\n",
       "      <td>-9</td>\n",
       "      <td>3020</td>\n",
       "      <td>0.332421</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>submission</td>\n",
       "      <td>100.0</td>\n",
       "      <td>ID00419637202311204720264_-9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.3724</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.332421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>ID00419637202311204720264</td>\n",
       "      <td>-8</td>\n",
       "      <td>3020</td>\n",
       "      <td>0.332421</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "      <td>submission</td>\n",
       "      <td>100.0</td>\n",
       "      <td>ID00419637202311204720264_-8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.092593</td>\n",
       "      <td>0.3724</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.332421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Patient  Weeks   FVC   Percent       Age   Sex  \\\n",
       "1540  ID00419637202311204720264    -12  3020  0.332421  0.615385  Male   \n",
       "1541  ID00419637202311204720264    -11  3020  0.332421  0.615385  Male   \n",
       "1542  ID00419637202311204720264    -10  3020  0.332421  0.615385  Male   \n",
       "1543  ID00419637202311204720264     -9  3020  0.332421  0.615385  Male   \n",
       "1544  ID00419637202311204720264     -8  3020  0.332421  0.615385  Male   \n",
       "\n",
       "     SmokingStatus       SPLIT  Confidence                   Patient_Week  \\\n",
       "1540     Ex-smoker  submission       100.0  ID00419637202311204720264_-12   \n",
       "1541     Ex-smoker  submission       100.0  ID00419637202311204720264_-11   \n",
       "1542     Ex-smoker  submission       100.0  ID00419637202311204720264_-10   \n",
       "1543     Ex-smoker  submission       100.0   ID00419637202311204720264_-9   \n",
       "1544     Ex-smoker  submission       100.0   ID00419637202311204720264_-8   \n",
       "\n",
       "      init_week  relative_week  init_week_FVC  Female  Male  Currently smokes  \\\n",
       "1540        6.0       0.067901         0.3724       0     1                 0   \n",
       "1541        6.0       0.074074         0.3724       0     1                 0   \n",
       "1542        6.0       0.080247         0.3724       0     1                 0   \n",
       "1543        6.0       0.086420         0.3724       0     1                 0   \n",
       "1544        6.0       0.092593         0.3724       0     1                 0   \n",
       "\n",
       "      Ex-smoker  Never smoked  init_week_Percent  \n",
       "1540          1             0           0.332421  \n",
       "1541          1             0           0.332421  \n",
       "1542          1             0           0.332421  \n",
       "1543          1             0           0.332421  \n",
       "1544          1             0           0.332421  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### image helpers\n",
    "def get_img_seq(pat_id, slice_count, data_dir, folder, img_size):\n",
    "        \n",
    "    images = []\n",
    "\n",
    "    slices = get_images(pat_id, slice_count, data_dir, folder)\n",
    "    scans = get_pixels_hu(slices)\n",
    "\n",
    "    for img_idx in range(slice_count):\n",
    "        img = scans[img_idx]\n",
    "\n",
    "        ## resize images to be same shape\n",
    "        img = cv2.resize(img, (img_size, img_size))\n",
    "\n",
    "        ## normalize the image pixels\n",
    "        img = (img - np.min(img)) / (np.max(img) - np.min(img))\n",
    "\n",
    "        #reshape for tesnor\n",
    "        img = np.repeat(img[..., np.newaxis], 3, -1)\n",
    "        images.append(img)     \n",
    "\n",
    "    return np.array(images).astype(np.float32)\n",
    "    \n",
    "def get_pixels_hu(scans):\n",
    "    '''\n",
    "    hu pixel is from\n",
    "    https://www.raddq.com/dicom-processing-segmentation-visualization-in-python/\n",
    "    '''\n",
    "    \n",
    "    image = np.stack([s.pixel_array for s in scans])\n",
    "    # Convert to int16 (from sometimes int16), \n",
    "    # should be possible as values should always be low enough (<32k)\n",
    "    image = image.astype(np.int16)\n",
    "\n",
    "    # Set outside-of-scan pixels to 1\n",
    "    # The intercept is usually -1024, so air is approximately 0\n",
    "    image[image == -2000] = 0\n",
    "    \n",
    "    # Convert to Hounsfield units (HU)\n",
    "    intercept = scans[0].RescaleIntercept\n",
    "    slope = scans[0].RescaleSlope\n",
    "    \n",
    "    if slope != 1:\n",
    "        image = slope * image.astype(np.float64)\n",
    "        image = image.astype(np.int16)\n",
    "        \n",
    "    image += np.int16(intercept)\n",
    "    \n",
    "    return np.array(image, dtype=np.int16)\n",
    "\n",
    "\n",
    "def get_images(pat_id, slice_count, data_dir, folder):\n",
    "    c_off = 2\n",
    "    path = f'{data_dir}/{folder}/{pat_id}'\n",
    "\n",
    "    file_names = sorted(os.listdir(path), key=lambda x: int(os.path.splitext(x)[0]))\n",
    "\n",
    "    idxs = [\n",
    "        int(i * len(file_names) / (slice_count + 2 * c_off)) \n",
    "        for i in range(slice_count + 2 * c_off)\n",
    "    ]\n",
    "\n",
    "    image_array = [\n",
    "        pydicom.read_file(path + '/' + file_names[idx])\n",
    "        for idx in idxs[c_off:-c_off]\n",
    "    ]\n",
    "\n",
    "    if len(image_array) < slice_count:\n",
    "        for i in range(slice_count - len(image_array)):\n",
    "            image_array.append(pydicom.read_file(path + '/' + os.listdir(path)[-1]))\n",
    "\n",
    "    return image_array\n",
    "\n",
    "######################################################\n",
    "## data generator, used to feed data to TensorFlow in batches\n",
    "######################################################\n",
    "\n",
    "class DataGen(tf.keras.utils.Sequence):\n",
    "    def __init__(\n",
    "        self, \n",
    "        df, \n",
    "        tab_features,\n",
    "        data_dir,\n",
    "        batch_size=8, \n",
    "        mode='fit', \n",
    "        shuffle=False, \n",
    "        cutoff=2,\n",
    "        folder='train',\n",
    "        slice_count=12, \n",
    "        img_size=224):\n",
    "\n",
    "        self.df = df\n",
    "        self.data_dir = data_dir\n",
    "        self.shuffle = shuffle\n",
    "        self.mode = mode\n",
    "        self.batch_size = batch_size\n",
    "        self.folder = folder\n",
    "        self.img_size = img_size\n",
    "        self.slice_count = slice_count\n",
    "        self.tab_features = tab_features\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "\n",
    "        return int(np.floor(len(self.df) / self.batch_size))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \n",
    "        self.indexes = np.arange(len(self.df))\n",
    "\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        batch_size = min(self.batch_size, len(self.df) - index * self.batch_size)\n",
    "        \n",
    "        X_img = np.zeros((batch_size, self.slice_count, self.img_size, self.img_size, 3), dtype=np.float32)\n",
    "        X_tab = self.df[index * self.batch_size : (index + 1) * self.batch_size][self.tab_features].values\n",
    "        pats_batch = self.df[index * self.batch_size : (index + 1) * self.batch_size]['Patient'].values\n",
    "        \n",
    "        for i, pat_id in enumerate(pats_batch):\n",
    "            imgs_seq = get_img_seq(pat_id, self.slice_count, self.data_dir, self.folder, self.img_size)\n",
    "            X_img[i, ] = imgs_seq\n",
    "\n",
    "        if self.mode == 'fit' or self.mode == 'test':\n",
    "            y = np.array(\n",
    "                self.df[index * self.batch_size : (index + 1) * self.batch_size]['FVC'].values, \n",
    "                dtype=np.float32\n",
    "            )\n",
    "\n",
    "            return (X_img, X_tab), y\n",
    "\n",
    "        elif self.mode == 'predict':\n",
    "            y = np.zeros(batch_size, dtype=np.float32)\n",
    "\n",
    "            return (X_img, X_tab), y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded: dropout_variance_v11b_batch_10_fold_0.h5\n",
      "Evaluate on test data\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 211.0601\n",
      "test loss, test acc: 211.0601043701172\n",
      "Predictions on test data\n",
      "5/5 [==============================] - 0s 30ms/step\n",
      "Test preds shape: (5, 1)\n",
      "Test preds sample: [2834.957]\n",
      "730/730 [==============================] - 24s 33ms/step\n",
      "predictions shape: (730, 1)\n",
      "predictions sample: [2861.0234]\n",
      "model loaded: dropout_variance_v11b_batch_10_fold_1.h5\n",
      "Evaluate on test data\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 221.6521\n",
      "test loss, test acc: 221.6521453857422\n",
      "Predictions on test data\n",
      "5/5 [==============================] - 0s 24ms/step\n",
      "Test preds shape: (5, 1)\n",
      "Test preds sample: [2908.4402]\n",
      "730/730 [==============================] - 24s 33ms/step\n",
      "predictions shape: (730, 1)\n",
      "predictions sample: [2917.7158]\n",
      "model loaded: dropout_variance_v11b_batch_10_fold_2.h5\n",
      "Evaluate on test data\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 210.0867\n",
      "test loss, test acc: 210.0867156982422\n",
      "Predictions on test data\n",
      "5/5 [==============================] - 0s 24ms/step\n",
      "Test preds shape: (5, 1)\n",
      "Test preds sample: [2821.4285]\n",
      "730/730 [==============================] - 24s 33ms/step\n",
      "predictions shape: (730, 1)\n",
      "predictions sample: [2845.0442]\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "## prediction time\n",
    "######################################################\n",
    "\n",
    "predictions = {}\n",
    "test_accuracy = {}\n",
    "test_predictions = {}\n",
    "\n",
    "for i in range(3):\n",
    "    \n",
    "    model_file = f'{MODEL}_fold_{i}.h5'\n",
    "    model = tf.keras.models.load_model(model_file)\n",
    "    print('model loaded:', model_file)\n",
    "\n",
    "    sub_datagen = DataGen(\n",
    "        df=subm,\n",
    "        tab_features=TRAINING_FEATURES,\n",
    "        data_dir=DATA_DIR,\n",
    "        batch_size=BATCH_PRED,\n",
    "        mode='predict', \n",
    "        shuffle=False, \n",
    "        folder='test',\n",
    "        slice_count=IMG_SLICES, \n",
    "        img_size=IMG_SIZE\n",
    "    )\n",
    "    \n",
    "    eval_datagen = DataGen(\n",
    "        df=test,\n",
    "        tab_features=TRAINING_FEATURES,\n",
    "        data_dir=DATA_DIR,\n",
    "        batch_size=BATCH_PRED,\n",
    "        mode='test', \n",
    "        shuffle=False, \n",
    "        folder='test',\n",
    "        slice_count=IMG_SLICES, \n",
    "        img_size=IMG_SIZE\n",
    "    )\n",
    "    \n",
    "    eval_preds_datagen = DataGen(\n",
    "        df=test,\n",
    "        tab_features=TRAINING_FEATURES,\n",
    "        data_dir=DATA_DIR,\n",
    "        batch_size=BATCH_PRED,\n",
    "        mode='predict', \n",
    "        shuffle=False, \n",
    "        folder='test',\n",
    "        slice_count=IMG_SLICES, \n",
    "        img_size=IMG_SIZE\n",
    "    )\n",
    "    \n",
    "    # Evaluate the model on the test data using `evaluate`\n",
    "    print(\"Evaluate on test data\")\n",
    "    test_acc = model.evaluate(eval_datagen)\n",
    "    print(\"test loss, test acc:\", test_acc)\n",
    "    test_accuracy['fold_' + str(i)] = test_acc\n",
    "    \n",
    "    # predict the test vals and compare to actual\n",
    "    print(\"Predictions on test data\")\n",
    "    test_preds = model.predict(eval_preds_datagen, verbose=1)\n",
    "    print('Test preds shape:', test_preds.shape)\n",
    "    print('Test preds sample:', test_preds[0])\n",
    "    test_predictions['fold_' + str(i) + '_predicted'] = test_preds.flatten()\n",
    "    test_predictions['fold_' + str(i) + '_actual'] = test.FVC\n",
    "    \n",
    "    preds_subm = model.predict(sub_datagen, verbose=1)\n",
    "    print('predictions shape:', preds_subm.shape)\n",
    "    print('predictions sample:', preds_subm[0])\n",
    "    \n",
    "    predictions['fold_' + str(i)] = preds_subm.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fold_0': 211.0601043701172,\n",
       " 'fold_1': 221.6521453857422,\n",
       " 'fold_2': 210.0867156982422}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold_0_predicted</th>\n",
       "      <th>fold_0_actual</th>\n",
       "      <th>fold_1_predicted</th>\n",
       "      <th>fold_1_actual</th>\n",
       "      <th>fold_2_predicted</th>\n",
       "      <th>fold_2_actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>2834.957031</td>\n",
       "      <td>3020</td>\n",
       "      <td>2908.440186</td>\n",
       "      <td>3020</td>\n",
       "      <td>2821.428467</td>\n",
       "      <td>3020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>2929.029785</td>\n",
       "      <td>2739</td>\n",
       "      <td>3002.823730</td>\n",
       "      <td>2739</td>\n",
       "      <td>2887.949463</td>\n",
       "      <td>2739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>2308.489746</td>\n",
       "      <td>1930</td>\n",
       "      <td>2501.883789</td>\n",
       "      <td>1930</td>\n",
       "      <td>2288.532471</td>\n",
       "      <td>1930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>3160.848633</td>\n",
       "      <td>3294</td>\n",
       "      <td>3185.474854</td>\n",
       "      <td>3294</td>\n",
       "      <td>3129.464600</td>\n",
       "      <td>3294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>2756.413330</td>\n",
       "      <td>2925</td>\n",
       "      <td>2872.531738</td>\n",
       "      <td>2925</td>\n",
       "      <td>2745.155273</td>\n",
       "      <td>2925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fold_0_predicted  fold_0_actual  fold_1_predicted  fold_1_actual  \\\n",
       "1535       2834.957031           3020       2908.440186           3020   \n",
       "1536       2929.029785           2739       3002.823730           2739   \n",
       "1537       2308.489746           1930       2501.883789           1930   \n",
       "1538       3160.848633           3294       3185.474854           3294   \n",
       "1539       2756.413330           2925       2872.531738           2925   \n",
       "\n",
       "      fold_2_predicted  fold_2_actual  \n",
       "1535       2821.428467           3020  \n",
       "1536       2887.949463           2739  \n",
       "1537       2288.532471           1930  \n",
       "1538       3129.464600           3294  \n",
       "1539       2745.155273           2925  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions_df = pd.DataFrame(test_predictions)\n",
    "test_predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm['FVC'] = subm_preds['means'].to_numpy()\n",
    "subm['Confidence'] = subm_preds['std'].to_numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
